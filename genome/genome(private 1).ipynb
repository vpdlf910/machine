{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b0081b-2671-4ff8-a8e8-a04ed8289dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "  Downloading category_encoders-2.6.0-py2.py3-none-any.whl (81 kB)\n",
      "     ---------------------------------------- 81.2/81.2 kB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from category_encoders) (1.21.5)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from category_encoders) (1.0.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from category_encoders) (0.13.2)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from category_encoders) (1.4.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from category_encoders) (1.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2022.1)\n",
      "Requirement already satisfied: six in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.9)\n",
      "Installing collected packages: category_encoders\n",
      "Successfully installed category_encoders-2.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274c0cac-b78c-4080-86d4-ee2690245eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "     -------------------------------------- 226.0/226.0 kB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     -------------------------------------- 298.0/298.0 kB 9.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.9.1)\n",
      "Installing collected packages: joblib, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0 joblib-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4db1fd4d-f200-42b4-9314-3d732fcbf632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.4-py3-none-win_amd64.whl (89.1 MB)\n",
      "     --------------------------------------- 89.1/89.1 MB 28.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\vpdlf910\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e230765a-9c06-4a4a-a2a2-b59e3c3df601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Windows-10-10.0.19045-SP0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.platform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454175ff-9589-4eb9-b632-b2e1ca187920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 24 00:41:48 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 528.24       Driver Version: 528.24       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   53C    P8     4W /  89W |   3391MiB /  4096MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     16316    C+G   ...rmouryCrateKeyControl.exe    N/A      |\n",
      "|    0   N/A  N/A     19960      C   ...thon\\Python310\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5589390e-7270-4921-8123-7be477102749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "620c63b8-97c2-49e8-94a5-58485ce4c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b194a651-0c68-434c-a605-bac63eca8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4de62e30-e2f5-4969-b05e-07be8ff0cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import category_encoders as ce\n",
    "from imblearn.over_sampling import BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b15ff7da-4427-459f-b5f3-3416cab65182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier , GradientBoostingClassifier, VotingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a799465-5c21-4593-b6cd-0d609331fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 26\n",
    "    \n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(CFG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "751ff3bc-0845-4f6a-94e3-321a4a20b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './open/'\n",
    "train = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "test = pd.read_csv(DATA_PATH + 'test.csv')\n",
    "snp = pd.read_csv(DATA_PATH + 'snp_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1465db7f-ba7b-422d-9648-7280f3e4d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(df):\n",
    "    if 'class' in df.columns:\n",
    "        df_x = df.drop(columns = ['id','class'])\n",
    "        df_y = df['class']\n",
    "        return df_x , df_y\n",
    "    else:\n",
    "        df_x = df.drop(columns= ['id'])\n",
    "        return df_x\n",
    "train_x , train_y = get_x_y(train)\n",
    "test_x = get_x_y(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40445099-1e81-42be-8f9e-9349373247c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='class', ylabel='count'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fa770a8-3b4f-47cd-842f-4a32cfe3a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.drop(columns = ['father','mother','gender'])\n",
    "test_x = test_x.drop(columns = ['father', 'mother', 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ba9dcaa-9a65-4bd5-966a-7f207ee5f17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP_id</th>\n",
       "      <th>name</th>\n",
       "      <th>chrom</th>\n",
       "      <th>cm</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SNP_01</td>\n",
       "      <td>BTA-19852-no-rs</td>\n",
       "      <td>2</td>\n",
       "      <td>67.05460</td>\n",
       "      <td>42986890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SNP_02</td>\n",
       "      <td>ARS-USMARC-Parent-DQ647190-rs29013632</td>\n",
       "      <td>6</td>\n",
       "      <td>31.15670</td>\n",
       "      <td>13897068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SNP_03</td>\n",
       "      <td>ARS-BFGL-NGS-117009</td>\n",
       "      <td>6</td>\n",
       "      <td>68.28920</td>\n",
       "      <td>44649549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SNP_04</td>\n",
       "      <td>ARS-BFGL-NGS-60567</td>\n",
       "      <td>6</td>\n",
       "      <td>77.87490</td>\n",
       "      <td>53826064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SNP_05</td>\n",
       "      <td>BovineHD0600017032</td>\n",
       "      <td>6</td>\n",
       "      <td>80.50150</td>\n",
       "      <td>61779512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SNP_06</td>\n",
       "      <td>BovineHD0600017424</td>\n",
       "      <td>6</td>\n",
       "      <td>80.59540</td>\n",
       "      <td>63048481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SNP_07</td>\n",
       "      <td>Hapmap49442-BTA-111073</td>\n",
       "      <td>6</td>\n",
       "      <td>80.78000</td>\n",
       "      <td>64037334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNP_08</td>\n",
       "      <td>BovineHD0600018638</td>\n",
       "      <td>6</td>\n",
       "      <td>82.68560</td>\n",
       "      <td>67510588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNP_09</td>\n",
       "      <td>ARS-BFGL-NGS-37727</td>\n",
       "      <td>6</td>\n",
       "      <td>86.87400</td>\n",
       "      <td>73092782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNP_10</td>\n",
       "      <td>BTB-01558306</td>\n",
       "      <td>7</td>\n",
       "      <td>62.06920</td>\n",
       "      <td>40827112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SNP_11</td>\n",
       "      <td>ARS-BFGL-NGS-44247</td>\n",
       "      <td>8</td>\n",
       "      <td>97.17310</td>\n",
       "      <td>92485682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SNP_12</td>\n",
       "      <td>Hapmap32827-BTA-146530</td>\n",
       "      <td>9</td>\n",
       "      <td>62.74630</td>\n",
       "      <td>55007839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SNP_13</td>\n",
       "      <td>BTB-00395482</td>\n",
       "      <td>9</td>\n",
       "      <td>63.41810</td>\n",
       "      <td>59692848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SNP_14</td>\n",
       "      <td>Hapmap40256-BTA-84189</td>\n",
       "      <td>9</td>\n",
       "      <td>66.81970</td>\n",
       "      <td>72822507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SNP_15</td>\n",
       "      <td>BovineHD1000000224</td>\n",
       "      <td>10</td>\n",
       "      <td>1.78774</td>\n",
       "      <td>814291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SNP_id                                   name  chrom        cm       pos\n",
       "0   SNP_01                        BTA-19852-no-rs      2  67.05460  42986890\n",
       "1   SNP_02  ARS-USMARC-Parent-DQ647190-rs29013632      6  31.15670  13897068\n",
       "2   SNP_03                    ARS-BFGL-NGS-117009      6  68.28920  44649549\n",
       "3   SNP_04                     ARS-BFGL-NGS-60567      6  77.87490  53826064\n",
       "4   SNP_05                     BovineHD0600017032      6  80.50150  61779512\n",
       "5   SNP_06                     BovineHD0600017424      6  80.59540  63048481\n",
       "6   SNP_07                 Hapmap49442-BTA-111073      6  80.78000  64037334\n",
       "7   SNP_08                     BovineHD0600018638      6  82.68560  67510588\n",
       "8   SNP_09                     ARS-BFGL-NGS-37727      6  86.87400  73092782\n",
       "9   SNP_10                           BTB-01558306      7  62.06920  40827112\n",
       "10  SNP_11                     ARS-BFGL-NGS-44247      8  97.17310  92485682\n",
       "11  SNP_12                 Hapmap32827-BTA-146530      9  62.74630  55007839\n",
       "12  SNP_13                           BTB-00395482      9  63.41810  59692848\n",
       "13  SNP_14                  Hapmap40256-BTA-84189      9  66.81970  72822507\n",
       "14  SNP_15                     BovineHD1000000224     10   1.78774    814291"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snp #DNA 염기서열에서 하나의 염기서열(A,T,G,C)의 차이를 보이는 유전적 변화 또는 변이를 단일 핵산염기 다형현상(Single Nucleotide polymorphism, SNP)이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbab16d7-aef6-43ab-b00f-1215c076843d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     SNP_01\n",
       "1     SNP_02\n",
       "2     SNP_03\n",
       "3     SNP_04\n",
       "4     SNP_05\n",
       "5     SNP_06\n",
       "6     SNP_07\n",
       "7     SNP_08\n",
       "8     SNP_09\n",
       "9     SNP_10\n",
       "10    SNP_11\n",
       "11    SNP_12\n",
       "12    SNP_13\n",
       "13    SNP_14\n",
       "14    SNP_15\n",
       "Name: SNP_id, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snp['SNP_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65da970b-6909-4833-80ef-220fe9869d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x['2_BTA'] = train_x['SNP_01']\n",
    "train_x['chrom_6'] = train_x['SNP_02'] + '-' + train_x['SNP_03'] + '-' + train_x['SNP_04'] + '-' + train_x['SNP_05'] + '-' + train_x['SNP_06'] + '-' + train_x['SNP_07'] + '-' + train_x['SNP_08'] + '-' + train_x['SNP_09']\n",
    "train_x['6_ARS_Parent'] = train_x['SNP_02']\n",
    "train_x['6_ARS_BFGL'] = train_x['SNP_03']+ '-' + train_x['SNP_04']+ '-' + train_x['SNP_09']\n",
    "train_x['6_BOVINE'] = train_x['SNP_05'] + '-' + train_x['SNP_06'] + '-' + train_x['SNP_08']\n",
    "train_x['6_HAPMAP'] = train_x['SNP_07']\n",
    "train_x['7_BTB'] = train_x['SNP_10']\n",
    "train_x['8_ARS'] = train_x['SNP_11']\n",
    "train_x['chrom_9'] = train_x['SNP_12'] + '-' + train_x['SNP_13'] + '-' + train_x['SNP_14']\n",
    "train_x['9_HAPMAP'] = train_x['SNP_12'] + '-' + train_x['SNP_14']\n",
    "train_x['9_BTB'] = train_x['SNP_13']\n",
    "train_x['10_BOVINE'] = train_x['SNP_15']\n",
    "train_x['SNP_total'] = train_x['SNP_01'] + '-' + train_x['SNP_02'] + '-' + train_x['SNP_03'] + '-' + train_x['SNP_04'] + '-' + train_x['SNP_05'] + '-' + train_x['SNP_06'] + '-' + train_x['SNP_07'] + '-' + train_x['SNP_08'] + '-' + train_x['SNP_09'] + '-' + train_x['SNP_10'] + '-' + train_x['SNP_11'] + '-' + train_x['SNP_12'] + '-' + train_x['SNP_13'] + '-' + train_x['SNP_14'] + '-' + train_x['SNP_15']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bd29352-3c20-402c-b447-f05e4d33d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x['2_BTA'] = test_x['SNP_01']\n",
    "test_x['chrom_6'] = test_x['SNP_02'] + '-' + test_x['SNP_03'] + '-' + test_x['SNP_04'] + '-' + test_x['SNP_05'] + '-' + test_x['SNP_06'] + '-' + test_x['SNP_07'] + '-' + test_x['SNP_08'] + '-' + test_x['SNP_09']\n",
    "test_x['6_ARS_Parent'] = test_x['SNP_02']\n",
    "test_x['6_ARS_BFGL'] = test_x['SNP_03']+ '-' + test_x['SNP_04']+ '-' + test_x['SNP_09']\n",
    "test_x['6_BOVINE'] = test_x['SNP_05'] + '-' + test_x['SNP_06'] + '-' + test_x['SNP_08']\n",
    "test_x['6_HAPMAP'] = test_x['SNP_07']\n",
    "test_x['7_BTB'] = test_x['SNP_10']\n",
    "test_x['8_ARS'] = test_x['SNP_11']\n",
    "test_x['chrom_9'] = test_x['SNP_12'] + '-' + test_x['SNP_13'] + '-' + test_x['SNP_14']\n",
    "test_x['9_HAPMAP'] = test_x['SNP_12'] + '-' + test_x['SNP_14']\n",
    "test_x['9_BTB'] = test_x['SNP_13']\n",
    "test_x['10_BOVINE'] = test_x['SNP_15']\n",
    "test_x['SNP_total'] = test_x['SNP_01'] + '-' + test_x['SNP_02'] + '-' + test_x['SNP_03'] + '-' + test_x['SNP_04'] + '-' + test_x['SNP_05'] + '-' + test_x['SNP_06'] + '-' + test_x['SNP_07'] + '-' + test_x['SNP_08'] + '-' + test_x['SNP_09'] + '-' + test_x['SNP_10'] + '-' + test_x['SNP_11'] + '-' + test_x['SNP_12'] + '-' + test_x['SNP_13'] + '-' + test_x['SNP_14'] + '-' + test_x['SNP_15']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e21fff4-fa1b-4b7e-bc35-705a12ea9c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blank(data_tr, data_te, columns):\n",
    "    for i in columns:\n",
    "        data_tr[i] = data_tr[i].apply(lambda x : x.replace(\" \", \"\"))\n",
    "        data_te[i] = data_te[i].apply(lambda x : x.replace(\" \", \"\"))\n",
    "    return data_tr, data_te\n",
    "target_columns = train_x.iloc[:,16:].columns.to_list()\n",
    "train_x.iloc[:,16:] , test_x.iloc[:,16:] = blank(train_x.iloc[:,16:], test_x.iloc[:,16:], target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b1f76a6-f855-47d1-ae6a-07151659ff76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2_BTA',\n",
       " 'chrom_6',\n",
       " '6_ARS_Parent',\n",
       " '6_ARS_BFGL',\n",
       " '6_BOVINE',\n",
       " '6_HAPMAP',\n",
       " '7_BTB',\n",
       " '8_ARS',\n",
       " 'chrom_9',\n",
       " '9_HAPMAP',\n",
       " '9_BTB',\n",
       " '10_BOVINE',\n",
       " 'SNP_total']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb22c46f-08fd-4e58-bdf5-dbe5bdaa3944",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x['concat'] = train_x.iloc[:,1:16].sum(axis= 1).apply(lambda x : x.replace(\" \", \"\"))\n",
    "train_x['numGC'] = train_x['concat'].apply(lambda x : x.count('C') + x.count('G'))\n",
    "train_x['numA'] = train_x['concat'].apply(lambda x : x.count('A'))\n",
    "train_x['numCG^2'] = train_x['numGC']**2\n",
    "train_x['sub'] = train_x['numGC'] - train_x['numA']\n",
    "train_x['H'] = train_x['numGC'] *3 + train_x['numA'] *2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9fa99ff-3d89-43ca-bb09-9e54c16b4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x['concat'] = test_x.iloc[:,1:16].sum(axis= 1).apply(lambda x : x.replace(\" \", \"\"))\n",
    "test_x['numGC'] = test_x['concat'].apply(lambda x : x.count('C') + x.count('G'))\n",
    "test_x['numA'] = test_x['concat'].apply(lambda x : x.count('A'))\n",
    "test_x['numCG^2'] = test_x['numGC']**2\n",
    "test_x['sub'] = test_x['numGC'] - test_x['numA']\n",
    "test_x['H'] = test_x['numGC'] *3 + test_x['numA'] *2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "301c15d0-afae-44cb-bdb3-ce117cf6c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x['trait'] = train_x['trait'].astype('object')\n",
    "test_x['trait'] = test_x['trait'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6b2046b-e95d-4807-a154-45fb5cbbd1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = train_x.select_dtypes(include= ['object']).columns.to_list()\n",
    "num_features = train_x.select_dtypes(exclude = ['object']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c97ccfc-b410-4f3c-b516-f82d4f907b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numGC', 'numA', 'numCG^2', 'sub', 'H']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ee0dd8a-920c-4ff5-9f89-11ef0b42d31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 262 entries, 0 to 261\n",
      "Data columns (total 35 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   trait         262 non-null    object\n",
      " 1   SNP_01        262 non-null    object\n",
      " 2   SNP_02        262 non-null    object\n",
      " 3   SNP_03        262 non-null    object\n",
      " 4   SNP_04        262 non-null    object\n",
      " 5   SNP_05        262 non-null    object\n",
      " 6   SNP_06        262 non-null    object\n",
      " 7   SNP_07        262 non-null    object\n",
      " 8   SNP_08        262 non-null    object\n",
      " 9   SNP_09        262 non-null    object\n",
      " 10  SNP_10        262 non-null    object\n",
      " 11  SNP_11        262 non-null    object\n",
      " 12  SNP_12        262 non-null    object\n",
      " 13  SNP_13        262 non-null    object\n",
      " 14  SNP_14        262 non-null    object\n",
      " 15  SNP_15        262 non-null    object\n",
      " 16  2_BTA         262 non-null    object\n",
      " 17  chrom_6       262 non-null    object\n",
      " 18  6_ARS_Parent  262 non-null    object\n",
      " 19  6_ARS_BFGL    262 non-null    object\n",
      " 20  6_BOVINE      262 non-null    object\n",
      " 21  6_HAPMAP      262 non-null    object\n",
      " 22  7_BTB         262 non-null    object\n",
      " 23  8_ARS         262 non-null    object\n",
      " 24  chrom_9       262 non-null    object\n",
      " 25  9_HAPMAP      262 non-null    object\n",
      " 26  9_BTB         262 non-null    object\n",
      " 27  10_BOVINE     262 non-null    object\n",
      " 28  SNP_total     262 non-null    object\n",
      " 29  concat        262 non-null    object\n",
      " 30  numGC         262 non-null    int64 \n",
      " 31  numA          262 non-null    int64 \n",
      " 32  numCG^2       262 non-null    int64 \n",
      " 33  sub           262 non-null    int64 \n",
      " 34  H             262 non-null    int64 \n",
      "dtypes: int64(5), object(30)\n",
      "memory usage: 71.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f782e39c-79cd-4a27-a9d2-b3c7a4d6c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ee081e6-096f-487f-b272-6d98d6adbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[num_features] = scaler.fit_transform(train_x[num_features])\n",
    "test_x[num_features] = scaler.transform(test_x[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "264b4d3b-272a-4018-b9f8-a9adf6d4093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_encoder_multiclass(X,X_t,y):\n",
    "    y = y.astype(str)\n",
    "    enc = ce.OneHotEncoder().fit(y)\n",
    "    y_onehot = enc.transform(y)\n",
    "    class_names = y_onehot.columns\n",
    "    X_obj = X.select_dtypes('object')\n",
    "    X_t_obj = X_t.select_dtypes('object')\n",
    "    X = X.select_dtypes(exclude= 'object')\n",
    "    X_t = X_t.select_dtypes(exclude='object')\n",
    "    for class_ in class_names:\n",
    "        enc = ce.CatBoostEncoder()\n",
    "        enc.fit(X_obj, y_onehot[class_])\n",
    "        temp = enc.transform(X_obj)\n",
    "        temp_t = enc.transform(X_t_obj)\n",
    "        temp.columns = [str(x) +'-'+str(class_) for x in temp.columns]\n",
    "        temp_t.columns = [str(x) + '-' +str(class_) for x in temp_t.columns]\n",
    "        X = pd.concat([X,temp], axis = 1)\n",
    "        X_t = pd.concat([X_t, temp_t], axis = 1)\n",
    "    return X, X_t\n",
    "train_x, test_x = catboost_encoder_multiclass(train_x,test_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7821869-c66e-4470-8406-2a445dc6bc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numGC</th>\n",
       "      <th>numA</th>\n",
       "      <th>numCG^2</th>\n",
       "      <th>sub</th>\n",
       "      <th>H</th>\n",
       "      <th>trait-class_1</th>\n",
       "      <th>SNP_01-class_1</th>\n",
       "      <th>SNP_02-class_1</th>\n",
       "      <th>SNP_03-class_1</th>\n",
       "      <th>SNP_04-class_1</th>\n",
       "      <th>...</th>\n",
       "      <th>6_BOVINE-class_3</th>\n",
       "      <th>6_HAPMAP-class_3</th>\n",
       "      <th>7_BTB-class_3</th>\n",
       "      <th>8_ARS-class_3</th>\n",
       "      <th>chrom_9-class_3</th>\n",
       "      <th>9_HAPMAP-class_3</th>\n",
       "      <th>9_BTB-class_3</th>\n",
       "      <th>10_BOVINE-class_3</th>\n",
       "      <th>SNP_total-class_3</th>\n",
       "      <th>concat-class_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.986104</td>\n",
       "      <td>-0.980678</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.596277</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052672</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.270327</td>\n",
       "      <td>1.270327</td>\n",
       "      <td>-1.179312</td>\n",
       "      <td>-1.270327</td>\n",
       "      <td>-1.270327</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.353265</td>\n",
       "      <td>0.596277</td>\n",
       "      <td>0.639087</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107779</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.191962</td>\n",
       "      <td>0.060433</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417657</td>\n",
       "      <td>0.417657</td>\n",
       "      <td>-0.520685</td>\n",
       "      <td>-0.417657</td>\n",
       "      <td>-0.417657</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.287685</td>\n",
       "      <td>-1.287685</td>\n",
       "      <td>1.361107</td>\n",
       "      <td>1.287685</td>\n",
       "      <td>1.287685</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934842</td>\n",
       "      <td>0.985834</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.669802</td>\n",
       "      <td>0.726336</td>\n",
       "      <td>0.558720</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.790417</td>\n",
       "      <td>0.754453</td>\n",
       "      <td>0.754453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.417657</td>\n",
       "      <td>0.417657</td>\n",
       "      <td>-0.520685</td>\n",
       "      <td>-0.417657</td>\n",
       "      <td>-0.417657</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.641533</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.210528</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>-0.701880</td>\n",
       "      <td>0.701880</td>\n",
       "      <td>-0.761136</td>\n",
       "      <td>-0.701880</td>\n",
       "      <td>-0.701880</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.353265</td>\n",
       "      <td>0.596277</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014631</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.020258</td>\n",
       "      <td>0.060433</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.986104</td>\n",
       "      <td>-0.980678</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.335088</td>\n",
       "      <td>0.639087</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107779</td>\n",
       "      <td>0.372722</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.210528</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1.287685</td>\n",
       "      <td>-1.287685</td>\n",
       "      <td>1.361107</td>\n",
       "      <td>1.287685</td>\n",
       "      <td>1.287685</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.353265</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107779</td>\n",
       "      <td>0.985834</td>\n",
       "      <td>0.733258</td>\n",
       "      <td>0.669802</td>\n",
       "      <td>0.967972</td>\n",
       "      <td>0.967972</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.790417</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.719237</td>\n",
       "      <td>-0.719237</td>\n",
       "      <td>0.650208</td>\n",
       "      <td>0.719237</td>\n",
       "      <td>0.719237</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934842</td>\n",
       "      <td>0.985834</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.891460</td>\n",
       "      <td>0.803335</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.790417</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.150790</td>\n",
       "      <td>-0.150790</td>\n",
       "      <td>0.022944</td>\n",
       "      <td>0.150790</td>\n",
       "      <td>0.150790</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.596277</td>\n",
       "      <td>0.639087</td>\n",
       "      <td>0.268702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.040754</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.210528</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        numGC      numA   numCG^2       sub         H  trait-class_1  \\\n",
       "0   -0.986104  0.986104 -0.980678 -0.986104 -0.986104       0.589872   \n",
       "1   -1.270327  1.270327 -1.179312 -1.270327 -1.270327       0.589872   \n",
       "2   -0.417657  0.417657 -0.520685 -0.417657 -0.417657       0.589872   \n",
       "3    1.287685 -1.287685  1.361107  1.287685  1.287685       0.006216   \n",
       "4   -0.417657  0.417657 -0.520685 -0.417657 -0.417657       0.589872   \n",
       "..        ...       ...       ...       ...       ...            ...   \n",
       "257 -0.701880  0.701880 -0.761136 -0.701880 -0.701880       0.589872   \n",
       "258 -0.986104  0.986104 -0.980678 -0.986104 -0.986104       0.589872   \n",
       "259  1.287685 -1.287685  1.361107  1.287685  1.287685       0.006216   \n",
       "260  0.719237 -0.719237  0.650208  0.719237  0.719237       0.006216   \n",
       "261  0.150790 -0.150790  0.022944  0.150790  0.150790       0.589872   \n",
       "\n",
       "     SNP_01-class_1  SNP_02-class_1  SNP_03-class_1  SNP_04-class_1  ...  \\\n",
       "0          0.629825        0.596277        0.198659        0.568459  ...   \n",
       "1          0.353265        0.596277        0.639087        0.400290  ...   \n",
       "2          0.629825        0.343441        0.198659        0.568459  ...   \n",
       "3          0.008532        0.343441        0.198659        0.568459  ...   \n",
       "4          0.629825        0.343441        0.641533        0.400290  ...   \n",
       "..              ...             ...             ...             ...  ...   \n",
       "257        0.353265        0.596277        0.198659        0.568459  ...   \n",
       "258        0.629825        0.335088        0.639087        0.400290  ...   \n",
       "259        0.353265        0.343441        0.198659        0.568459  ...   \n",
       "260        0.008532        0.343441        0.198659        0.568459  ...   \n",
       "261        0.629825        0.596277        0.639087        0.268702  ...   \n",
       "\n",
       "     6_BOVINE-class_3  6_HAPMAP-class_3  7_BTB-class_3  8_ARS-class_3  \\\n",
       "0            0.052672          0.001606       0.021469       0.136736   \n",
       "1            0.107779          0.001606       0.496570       0.003135   \n",
       "2            0.043893          0.001606       0.496570       0.003135   \n",
       "3            0.934842          0.985834       0.496570       0.669802   \n",
       "4            0.043893          0.001606       0.021469       0.003135   \n",
       "..                ...               ...            ...            ...   \n",
       "257          0.014631          0.001606       0.021469       0.136736   \n",
       "258          0.107779          0.372722       0.496570       0.136736   \n",
       "259          0.107779          0.985834       0.733258       0.669802   \n",
       "260          0.934842          0.985834       0.496570       0.136736   \n",
       "261          0.043893          0.001606       0.021469       0.003135   \n",
       "\n",
       "     chrom_9-class_3  9_HAPMAP-class_3  9_BTB-class_3  10_BOVINE-class_3  \\\n",
       "0           0.007118          0.010441       0.004969           0.039476   \n",
       "1           0.191962          0.060433       0.571236           0.039476   \n",
       "2           0.007118          0.010441       0.004969           0.039476   \n",
       "3           0.726336          0.558720       0.571236           0.790417   \n",
       "4           0.004788          0.010441       0.033993           0.210528   \n",
       "..               ...               ...            ...                ...   \n",
       "257         0.020258          0.060433       0.004969           0.039476   \n",
       "258         0.004788          0.010441       0.033993           0.210528   \n",
       "259         0.967972          0.967972       0.571236           0.790417   \n",
       "260         0.891460          0.803335       0.571236           0.790417   \n",
       "261         0.040754          0.010441       0.571236           0.210528   \n",
       "\n",
       "     SNP_total-class_3  concat-class_3  \n",
       "0             0.263359        0.263359  \n",
       "1             0.263359        0.263359  \n",
       "2             0.263359        0.263359  \n",
       "3             0.754453        0.754453  \n",
       "4             0.263359        0.263359  \n",
       "..                 ...             ...  \n",
       "257           0.263359        0.263359  \n",
       "258           0.263359        0.263359  \n",
       "259           0.263359        0.263359  \n",
       "260           0.263359        0.263359  \n",
       "261           0.263359        0.263359  \n",
       "\n",
       "[262 rows x 95 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "181f4cf3-66e3-4cdd-a77c-42e532e24921",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x , train_y = BorderlineSMOTE(random_state= CFG.SEED).fit_resample(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86b9e419-419e-45bf-94f5-a40af32ca036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numGC</th>\n",
       "      <th>numA</th>\n",
       "      <th>numCG^2</th>\n",
       "      <th>sub</th>\n",
       "      <th>H</th>\n",
       "      <th>trait-class_1</th>\n",
       "      <th>SNP_01-class_1</th>\n",
       "      <th>SNP_02-class_1</th>\n",
       "      <th>SNP_03-class_1</th>\n",
       "      <th>SNP_04-class_1</th>\n",
       "      <th>...</th>\n",
       "      <th>6_BOVINE-class_3</th>\n",
       "      <th>6_HAPMAP-class_3</th>\n",
       "      <th>7_BTB-class_3</th>\n",
       "      <th>8_ARS-class_3</th>\n",
       "      <th>chrom_9-class_3</th>\n",
       "      <th>9_HAPMAP-class_3</th>\n",
       "      <th>9_BTB-class_3</th>\n",
       "      <th>10_BOVINE-class_3</th>\n",
       "      <th>SNP_total-class_3</th>\n",
       "      <th>concat-class_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.986104</td>\n",
       "      <td>-0.980678</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.596277</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052672</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.270327</td>\n",
       "      <td>1.270327</td>\n",
       "      <td>-1.179312</td>\n",
       "      <td>-1.270327</td>\n",
       "      <td>-1.270327</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.353265</td>\n",
       "      <td>0.596277</td>\n",
       "      <td>0.639087</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107779</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.191962</td>\n",
       "      <td>0.060433</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417657</td>\n",
       "      <td>0.417657</td>\n",
       "      <td>-0.520685</td>\n",
       "      <td>-0.417657</td>\n",
       "      <td>-0.417657</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.287685</td>\n",
       "      <td>-1.287685</td>\n",
       "      <td>1.361107</td>\n",
       "      <td>1.287685</td>\n",
       "      <td>1.287685</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934842</td>\n",
       "      <td>0.985834</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.669802</td>\n",
       "      <td>0.726336</td>\n",
       "      <td>0.558720</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.790417</td>\n",
       "      <td>0.754453</td>\n",
       "      <td>0.754453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.417657</td>\n",
       "      <td>0.417657</td>\n",
       "      <td>-0.520685</td>\n",
       "      <td>-0.417657</td>\n",
       "      <td>-0.417657</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.641533</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.210528</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>-0.701880</td>\n",
       "      <td>0.701880</td>\n",
       "      <td>-0.761136</td>\n",
       "      <td>-0.701880</td>\n",
       "      <td>-0.701880</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.335088</td>\n",
       "      <td>0.639087</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091999</td>\n",
       "      <td>0.044820</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.121179</td>\n",
       "      <td>0.009507</td>\n",
       "      <td>0.054611</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.059394</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>-0.636502</td>\n",
       "      <td>0.636502</td>\n",
       "      <td>-0.705826</td>\n",
       "      <td>-0.636502</td>\n",
       "      <td>-0.636502</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.335088</td>\n",
       "      <td>0.639087</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044342</td>\n",
       "      <td>0.372722</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.156485</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.171182</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.082686</td>\n",
       "      <td>-0.082686</td>\n",
       "      <td>-0.044692</td>\n",
       "      <td>0.082686</td>\n",
       "      <td>0.082686</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.419533</td>\n",
       "      <td>0.535693</td>\n",
       "      <td>0.639673</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099721</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.135311</td>\n",
       "      <td>0.510058</td>\n",
       "      <td>0.191962</td>\n",
       "      <td>0.060433</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.210528</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.986104</td>\n",
       "      <td>-0.980678</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.335088</td>\n",
       "      <td>0.244382</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491858</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.055243</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.057233</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-0.470607</td>\n",
       "      <td>0.470607</td>\n",
       "      <td>-0.565480</td>\n",
       "      <td>-0.470607</td>\n",
       "      <td>-0.470607</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.335088</td>\n",
       "      <td>0.639087</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023206</td>\n",
       "      <td>0.372722</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.545604</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>0.051119</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.071342</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        numGC      numA   numCG^2       sub         H  trait-class_1  \\\n",
       "0   -0.986104  0.986104 -0.980678 -0.986104 -0.986104       0.589872   \n",
       "1   -1.270327  1.270327 -1.179312 -1.270327 -1.270327       0.589872   \n",
       "2   -0.417657  0.417657 -0.520685 -0.417657 -0.417657       0.589872   \n",
       "3    1.287685 -1.287685  1.361107  1.287685  1.287685       0.006216   \n",
       "4   -0.417657  0.417657 -0.520685 -0.417657 -0.417657       0.589872   \n",
       "..        ...       ...       ...       ...       ...            ...   \n",
       "292 -0.701880  0.701880 -0.761136 -0.701880 -0.701880       0.589872   \n",
       "293 -0.636502  0.636502 -0.705826 -0.636502 -0.636502       0.589872   \n",
       "294  0.082686 -0.082686 -0.044692  0.082686  0.082686       0.589872   \n",
       "295 -0.986104  0.986104 -0.980678 -0.986104 -0.986104       0.589872   \n",
       "296 -0.470607  0.470607 -0.565480 -0.470607 -0.470607       0.589872   \n",
       "\n",
       "     SNP_01-class_1  SNP_02-class_1  SNP_03-class_1  SNP_04-class_1  ...  \\\n",
       "0          0.629825        0.596277        0.198659        0.568459  ...   \n",
       "1          0.353265        0.596277        0.639087        0.400290  ...   \n",
       "2          0.629825        0.343441        0.198659        0.568459  ...   \n",
       "3          0.008532        0.343441        0.198659        0.568459  ...   \n",
       "4          0.629825        0.343441        0.641533        0.400290  ...   \n",
       "..              ...             ...             ...             ...  ...   \n",
       "292        0.629825        0.335088        0.639087        0.400290  ...   \n",
       "293        0.629825        0.335088        0.639087        0.400290  ...   \n",
       "294        0.419533        0.535693        0.639673        0.400290  ...   \n",
       "295        0.629825        0.335088        0.244382        0.551000  ...   \n",
       "296        0.629825        0.335088        0.639087        0.400290  ...   \n",
       "\n",
       "     6_BOVINE-class_3  6_HAPMAP-class_3  7_BTB-class_3  8_ARS-class_3  \\\n",
       "0            0.052672          0.001606       0.021469       0.136736   \n",
       "1            0.107779          0.001606       0.496570       0.003135   \n",
       "2            0.043893          0.001606       0.496570       0.003135   \n",
       "3            0.934842          0.985834       0.496570       0.669802   \n",
       "4            0.043893          0.001606       0.021469       0.003135   \n",
       "..                ...               ...            ...            ...   \n",
       "292          0.091999          0.044820       0.021469       0.121179   \n",
       "293          0.044342          0.372722       0.021469       0.156485   \n",
       "294          0.099721          0.001606       0.135311       0.510058   \n",
       "295          0.491858          0.001606       0.021469       0.136736   \n",
       "296          0.023206          0.372722       0.021469       0.545604   \n",
       "\n",
       "     chrom_9-class_3  9_HAPMAP-class_3  9_BTB-class_3  10_BOVINE-class_3  \\\n",
       "0           0.007118          0.010441       0.004969           0.039476   \n",
       "1           0.191962          0.060433       0.571236           0.039476   \n",
       "2           0.007118          0.010441       0.004969           0.039476   \n",
       "3           0.726336          0.558720       0.571236           0.790417   \n",
       "4           0.004788          0.010441       0.033993           0.210528   \n",
       "..               ...               ...            ...                ...   \n",
       "292         0.009507          0.054611       0.033993           0.059394   \n",
       "293         0.006017          0.021940       0.033993           0.171182   \n",
       "294         0.191962          0.060433       0.571236           0.210528   \n",
       "295         0.009575          0.055243       0.033993           0.057233   \n",
       "296         0.009134          0.051119       0.033993           0.071342   \n",
       "\n",
       "     SNP_total-class_3  concat-class_3  \n",
       "0             0.263359        0.263359  \n",
       "1             0.263359        0.263359  \n",
       "2             0.263359        0.263359  \n",
       "3             0.754453        0.754453  \n",
       "4             0.263359        0.263359  \n",
       "..                 ...             ...  \n",
       "292           0.263359        0.263359  \n",
       "293           0.263359        0.263359  \n",
       "294           0.263359        0.263359  \n",
       "295           0.263359        0.263359  \n",
       "296           0.263359        0.263359  \n",
       "\n",
       "[297 rows x 95 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f58cc99c-33ae-451f-b426-76eda9557f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numGC</th>\n",
       "      <th>numA</th>\n",
       "      <th>numCG^2</th>\n",
       "      <th>sub</th>\n",
       "      <th>H</th>\n",
       "      <th>trait-class_1</th>\n",
       "      <th>SNP_01-class_1</th>\n",
       "      <th>SNP_02-class_1</th>\n",
       "      <th>SNP_03-class_1</th>\n",
       "      <th>SNP_04-class_1</th>\n",
       "      <th>...</th>\n",
       "      <th>6_BOVINE-class_3</th>\n",
       "      <th>6_HAPMAP-class_3</th>\n",
       "      <th>7_BTB-class_3</th>\n",
       "      <th>8_ARS-class_3</th>\n",
       "      <th>chrom_9-class_3</th>\n",
       "      <th>9_HAPMAP-class_3</th>\n",
       "      <th>9_BTB-class_3</th>\n",
       "      <th>10_BOVINE-class_3</th>\n",
       "      <th>SNP_total-class_3</th>\n",
       "      <th>concat-class_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.719237</td>\n",
       "      <td>-0.719237</td>\n",
       "      <td>0.650208</td>\n",
       "      <td>0.719237</td>\n",
       "      <td>0.719237</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.353265</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107779</td>\n",
       "      <td>0.985834</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.891460</td>\n",
       "      <td>0.803335</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.210528</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417657</td>\n",
       "      <td>0.417657</td>\n",
       "      <td>-0.520685</td>\n",
       "      <td>-0.417657</td>\n",
       "      <td>-0.417657</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.596277</td>\n",
       "      <td>0.641533</td>\n",
       "      <td>0.268702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.701880</td>\n",
       "      <td>0.701880</td>\n",
       "      <td>-0.761136</td>\n",
       "      <td>-0.701880</td>\n",
       "      <td>-0.701880</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.596277</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536350</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.191962</td>\n",
       "      <td>0.060433</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.790417</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.986104</td>\n",
       "      <td>-0.980678</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.596277</td>\n",
       "      <td>0.639087</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>0.060433</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.287685</td>\n",
       "      <td>-1.287685</td>\n",
       "      <td>1.361107</td>\n",
       "      <td>1.287685</td>\n",
       "      <td>1.287685</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.268702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934842</td>\n",
       "      <td>0.985834</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.669802</td>\n",
       "      <td>0.191962</td>\n",
       "      <td>0.060433</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.790417</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.150790</td>\n",
       "      <td>-0.150790</td>\n",
       "      <td>0.022944</td>\n",
       "      <td>0.150790</td>\n",
       "      <td>0.150790</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.353265</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.641533</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015492</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.669802</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.210528</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-1.838774</td>\n",
       "      <td>1.838774</td>\n",
       "      <td>-1.513852</td>\n",
       "      <td>-1.838774</td>\n",
       "      <td>-1.838774</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.335088</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536350</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.210528</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.986104</td>\n",
       "      <td>-0.980678</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.335088</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536350</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.790417</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-0.133433</td>\n",
       "      <td>0.133433</td>\n",
       "      <td>-0.259325</td>\n",
       "      <td>-0.133433</td>\n",
       "      <td>-0.133433</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.353265</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.639087</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.435014</td>\n",
       "      <td>-0.435014</td>\n",
       "      <td>0.326121</td>\n",
       "      <td>0.435014</td>\n",
       "      <td>0.435014</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.641533</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052672</td>\n",
       "      <td>0.372722</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.669802</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        numGC      numA   numCG^2       sub         H  trait-class_1  \\\n",
       "0    0.719237 -0.719237  0.650208  0.719237  0.719237       0.006216   \n",
       "1   -0.417657  0.417657 -0.520685 -0.417657 -0.417657       0.589872   \n",
       "2   -0.701880  0.701880 -0.761136 -0.701880 -0.701880       0.589872   \n",
       "3   -0.986104  0.986104 -0.980678 -0.986104 -0.986104       0.589872   \n",
       "4    1.287685 -1.287685  1.361107  1.287685  1.287685       0.006216   \n",
       "..        ...       ...       ...       ...       ...            ...   \n",
       "170  0.150790 -0.150790  0.022944  0.150790  0.150790       0.589872   \n",
       "171 -1.838774  1.838774 -1.513852 -1.838774 -1.838774       0.589872   \n",
       "172 -0.986104  0.986104 -0.980678 -0.986104 -0.986104       0.589872   \n",
       "173 -0.133433  0.133433 -0.259325 -0.133433 -0.133433       0.589872   \n",
       "174  0.435014 -0.435014  0.326121  0.435014  0.435014       0.589872   \n",
       "\n",
       "     SNP_01-class_1  SNP_02-class_1  SNP_03-class_1  SNP_04-class_1  ...  \\\n",
       "0          0.353265        0.343441        0.198659        0.568459  ...   \n",
       "1          0.629825        0.596277        0.641533        0.268702  ...   \n",
       "2          0.629825        0.596277        0.198659        0.400290  ...   \n",
       "3          0.629825        0.596277        0.639087        0.400290  ...   \n",
       "4          0.008532        0.343441        0.198659        0.268702  ...   \n",
       "..              ...             ...             ...             ...  ...   \n",
       "170        0.353265        0.343441        0.641533        0.400290  ...   \n",
       "171        0.629825        0.335088        0.198659        0.400290  ...   \n",
       "172        0.629825        0.335088        0.198659        0.400290  ...   \n",
       "173        0.353265        0.343441        0.639087        0.568459  ...   \n",
       "174        0.629825        0.343441        0.641533        0.568459  ...   \n",
       "\n",
       "     6_BOVINE-class_3  6_HAPMAP-class_3  7_BTB-class_3  8_ARS-class_3  \\\n",
       "0            0.107779          0.985834       0.496570       0.136736   \n",
       "1            0.043893          0.001606       0.021469       0.136736   \n",
       "2            0.536350          0.001606       0.496570       0.003135   \n",
       "3            0.043893          0.001606       0.021469       0.003135   \n",
       "4            0.934842          0.985834       0.496570       0.669802   \n",
       "..                ...               ...            ...            ...   \n",
       "170          0.015492          0.001606       0.021469       0.669802   \n",
       "171          0.536350          0.001606       0.496570       0.003135   \n",
       "172          0.536350          0.001606       0.021469       0.136736   \n",
       "173          0.043893          0.001606       0.021469       0.136736   \n",
       "174          0.052672          0.372722       0.021469       0.669802   \n",
       "\n",
       "     chrom_9-class_3  9_HAPMAP-class_3  9_BTB-class_3  10_BOVINE-class_3  \\\n",
       "0           0.891460          0.803335       0.571236           0.210528   \n",
       "1           0.007118          0.010441       0.004969           0.039476   \n",
       "2           0.191962          0.060433       0.571236           0.790417   \n",
       "3           0.010129          0.060433       0.033993           0.039476   \n",
       "4           0.191962          0.060433       0.571236           0.790417   \n",
       "..               ...               ...            ...                ...   \n",
       "170         0.007118          0.010441       0.004969           0.210528   \n",
       "171         0.004788          0.010441       0.033993           0.210528   \n",
       "172         0.004788          0.010441       0.033993           0.790417   \n",
       "173         0.007118          0.010441       0.004969           0.039476   \n",
       "174         0.007118          0.010441       0.004969           0.039476   \n",
       "\n",
       "     SNP_total-class_3  concat-class_3  \n",
       "0             0.263359        0.263359  \n",
       "1             0.263359        0.263359  \n",
       "2             0.263359        0.263359  \n",
       "3             0.263359        0.263359  \n",
       "4             0.263359        0.263359  \n",
       "..                 ...             ...  \n",
       "170           0.263359        0.263359  \n",
       "171           0.263359        0.263359  \n",
       "172           0.263359        0.263359  \n",
       "173           0.263359        0.263359  \n",
       "174           0.263359        0.263359  \n",
       "\n",
       "[175 rows x 95 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c9011f0-e0db-4989-90f4-66130d0f6ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_le = LabelEncoder()\n",
    "train_y = class_le.fit_transform(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be8660fa-0b46-4919-9a6b-92098e691414",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(DATA_PATH+ 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e0bfc1f-3519-4f6d-8568-198417696f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('bag' , BaggingClassifier(random_state = CFG.SEED)),\n",
    "    ('dt', DecisionTreeClassifier(random_state = CFG.SEED)),\n",
    "    ('rc', RidgeClassifier(random_state = CFG.SEED)),\n",
    "    ('xgb', XGBClassifier(random_state = CFG.SEED)),\n",
    "    ('lgb', LGBMClassifier(random_state = CFG.SEED)),\n",
    "    ('gb', GradientBoostingClassifier(random_state = CFG.SEED)),\n",
    "    ('svc', SVC(random_state = CFG.SEED)),\n",
    "    ('rcc', RidgeClassifierCV()),\n",
    "    ('rf', RandomForestClassifier(random_state=CFG.SEED))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc919657-7ed9-4a55-a392-ed381ec759b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('bag', BaggingClassifier(random_state=26)),\n",
       "                             ('dt', DecisionTreeClassifier(random_state=26)),\n",
       "                             ('rc', RidgeClassifier(random_state=26)),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_me...\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=26, ...)),\n",
       "                             ('lgb', LGBMClassifier(random_state=26)),\n",
       "                             ('gb',\n",
       "                              GradientBoostingClassifier(random_state=26)),\n",
       "                             ('svc', SVC(random_state=26)),\n",
       "                             ('rcc',\n",
       "                              RidgeClassifierCV(alphas=array([ 0.1,  1. , 10. ]))),\n",
       "                             ('rf', RandomForestClassifier(random_state=26))],\n",
       "                 weights=[1, 1, 1, 2, 1, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = VotingClassifier(models, voting = 'hard' , weights = [1,1,1,2,1,1,1,1,2])\n",
    "best_model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd1b938e-6ebd-4b4c-be0a-8b57c50fc57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numGC</th>\n",
       "      <th>numA</th>\n",
       "      <th>numCG^2</th>\n",
       "      <th>sub</th>\n",
       "      <th>H</th>\n",
       "      <th>trait-class_1</th>\n",
       "      <th>SNP_01-class_1</th>\n",
       "      <th>SNP_02-class_1</th>\n",
       "      <th>SNP_03-class_1</th>\n",
       "      <th>SNP_04-class_1</th>\n",
       "      <th>...</th>\n",
       "      <th>6_BOVINE-class_3</th>\n",
       "      <th>6_HAPMAP-class_3</th>\n",
       "      <th>7_BTB-class_3</th>\n",
       "      <th>8_ARS-class_3</th>\n",
       "      <th>chrom_9-class_3</th>\n",
       "      <th>9_HAPMAP-class_3</th>\n",
       "      <th>9_BTB-class_3</th>\n",
       "      <th>10_BOVINE-class_3</th>\n",
       "      <th>SNP_total-class_3</th>\n",
       "      <th>concat-class_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.719237</td>\n",
       "      <td>-0.719237</td>\n",
       "      <td>0.650208</td>\n",
       "      <td>0.719237</td>\n",
       "      <td>0.719237</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.353265</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107779</td>\n",
       "      <td>0.985834</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.891460</td>\n",
       "      <td>0.803335</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.210528</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417657</td>\n",
       "      <td>0.417657</td>\n",
       "      <td>-0.520685</td>\n",
       "      <td>-0.417657</td>\n",
       "      <td>-0.417657</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.596277</td>\n",
       "      <td>0.641533</td>\n",
       "      <td>0.268702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.701880</td>\n",
       "      <td>0.701880</td>\n",
       "      <td>-0.761136</td>\n",
       "      <td>-0.701880</td>\n",
       "      <td>-0.701880</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.596277</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536350</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.191962</td>\n",
       "      <td>0.060433</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.790417</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.986104</td>\n",
       "      <td>-0.980678</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.596277</td>\n",
       "      <td>0.639087</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>0.060433</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.287685</td>\n",
       "      <td>-1.287685</td>\n",
       "      <td>1.361107</td>\n",
       "      <td>1.287685</td>\n",
       "      <td>1.287685</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.268702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934842</td>\n",
       "      <td>0.985834</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.669802</td>\n",
       "      <td>0.191962</td>\n",
       "      <td>0.060433</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.790417</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.150790</td>\n",
       "      <td>-0.150790</td>\n",
       "      <td>0.022944</td>\n",
       "      <td>0.150790</td>\n",
       "      <td>0.150790</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.353265</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.641533</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015492</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.669802</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.210528</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-1.838774</td>\n",
       "      <td>1.838774</td>\n",
       "      <td>-1.513852</td>\n",
       "      <td>-1.838774</td>\n",
       "      <td>-1.838774</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.335088</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536350</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.496570</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.210528</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.986104</td>\n",
       "      <td>-0.980678</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>-0.986104</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.335088</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536350</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.790417</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-0.133433</td>\n",
       "      <td>0.133433</td>\n",
       "      <td>-0.259325</td>\n",
       "      <td>-0.133433</td>\n",
       "      <td>-0.133433</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.353265</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.639087</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.435014</td>\n",
       "      <td>-0.435014</td>\n",
       "      <td>0.326121</td>\n",
       "      <td>0.435014</td>\n",
       "      <td>0.435014</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.641533</td>\n",
       "      <td>0.568459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052672</td>\n",
       "      <td>0.372722</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.669802</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.263359</td>\n",
       "      <td>0.263359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        numGC      numA   numCG^2       sub         H  trait-class_1  \\\n",
       "0    0.719237 -0.719237  0.650208  0.719237  0.719237       0.006216   \n",
       "1   -0.417657  0.417657 -0.520685 -0.417657 -0.417657       0.589872   \n",
       "2   -0.701880  0.701880 -0.761136 -0.701880 -0.701880       0.589872   \n",
       "3   -0.986104  0.986104 -0.980678 -0.986104 -0.986104       0.589872   \n",
       "4    1.287685 -1.287685  1.361107  1.287685  1.287685       0.006216   \n",
       "..        ...       ...       ...       ...       ...            ...   \n",
       "170  0.150790 -0.150790  0.022944  0.150790  0.150790       0.589872   \n",
       "171 -1.838774  1.838774 -1.513852 -1.838774 -1.838774       0.589872   \n",
       "172 -0.986104  0.986104 -0.980678 -0.986104 -0.986104       0.589872   \n",
       "173 -0.133433  0.133433 -0.259325 -0.133433 -0.133433       0.589872   \n",
       "174  0.435014 -0.435014  0.326121  0.435014  0.435014       0.589872   \n",
       "\n",
       "     SNP_01-class_1  SNP_02-class_1  SNP_03-class_1  SNP_04-class_1  ...  \\\n",
       "0          0.353265        0.343441        0.198659        0.568459  ...   \n",
       "1          0.629825        0.596277        0.641533        0.268702  ...   \n",
       "2          0.629825        0.596277        0.198659        0.400290  ...   \n",
       "3          0.629825        0.596277        0.639087        0.400290  ...   \n",
       "4          0.008532        0.343441        0.198659        0.268702  ...   \n",
       "..              ...             ...             ...             ...  ...   \n",
       "170        0.353265        0.343441        0.641533        0.400290  ...   \n",
       "171        0.629825        0.335088        0.198659        0.400290  ...   \n",
       "172        0.629825        0.335088        0.198659        0.400290  ...   \n",
       "173        0.353265        0.343441        0.639087        0.568459  ...   \n",
       "174        0.629825        0.343441        0.641533        0.568459  ...   \n",
       "\n",
       "     6_BOVINE-class_3  6_HAPMAP-class_3  7_BTB-class_3  8_ARS-class_3  \\\n",
       "0            0.107779          0.985834       0.496570       0.136736   \n",
       "1            0.043893          0.001606       0.021469       0.136736   \n",
       "2            0.536350          0.001606       0.496570       0.003135   \n",
       "3            0.043893          0.001606       0.021469       0.003135   \n",
       "4            0.934842          0.985834       0.496570       0.669802   \n",
       "..                ...               ...            ...            ...   \n",
       "170          0.015492          0.001606       0.021469       0.669802   \n",
       "171          0.536350          0.001606       0.496570       0.003135   \n",
       "172          0.536350          0.001606       0.021469       0.136736   \n",
       "173          0.043893          0.001606       0.021469       0.136736   \n",
       "174          0.052672          0.372722       0.021469       0.669802   \n",
       "\n",
       "     chrom_9-class_3  9_HAPMAP-class_3  9_BTB-class_3  10_BOVINE-class_3  \\\n",
       "0           0.891460          0.803335       0.571236           0.210528   \n",
       "1           0.007118          0.010441       0.004969           0.039476   \n",
       "2           0.191962          0.060433       0.571236           0.790417   \n",
       "3           0.010129          0.060433       0.033993           0.039476   \n",
       "4           0.191962          0.060433       0.571236           0.790417   \n",
       "..               ...               ...            ...                ...   \n",
       "170         0.007118          0.010441       0.004969           0.210528   \n",
       "171         0.004788          0.010441       0.033993           0.210528   \n",
       "172         0.004788          0.010441       0.033993           0.790417   \n",
       "173         0.007118          0.010441       0.004969           0.039476   \n",
       "174         0.007118          0.010441       0.004969           0.039476   \n",
       "\n",
       "     SNP_total-class_3  concat-class_3  \n",
       "0             0.263359        0.263359  \n",
       "1             0.263359        0.263359  \n",
       "2             0.263359        0.263359  \n",
       "3             0.263359        0.263359  \n",
       "4             0.263359        0.263359  \n",
       "..                 ...             ...  \n",
       "170           0.263359        0.263359  \n",
       "171           0.263359        0.263359  \n",
       "172           0.263359        0.263359  \n",
       "173           0.263359        0.263359  \n",
       "174           0.263359        0.263359  \n",
       "\n",
       "[175 rows x 95 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ade3a7cc-52bb-43a9-9fb9-1c9b9267252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = class_le.inverse_transform(best_model.predict(test_x))\n",
    "submit['class'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02133e46-726a-47c3-8390-951022f33563",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('Fine.20.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18162a8-fe0f-4c57-94ef-8ff7f5456bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
